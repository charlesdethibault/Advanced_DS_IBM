{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Keras exercise\n\nIn this exercise you will be creating a Keras model by loading a data set, preprocessing input data, building a Sequential Keras model and compiling the model with a training configuration. Afterwards, you train your model on the training data and evaluate it on the test set. To finish this exercise, you will past the accuracy of your model to the Coursera grader.\n\nThis notebook is tested in IBM Watson Studio under python 3.6\n\n##\u00a0Data\n\nFor this exercise we will use the Reuters newswire dataset. This dataset consists of 11,228 newswires from the Reuters news agency. Each wire is encoded as a sequence of word indexes, just as in the IMDB data we encountered in lecture 5 of this series. Moreover, each wire is categorised into one of 46 topics, which will serve as our label. This dataset is available through the Keras API.\n\n## Goal\n\nWe want to create a Multi-layer perceptron (MLP) using Keras which we can train to classify news items into the specified 46 topics.\n\n## Instructions\n\nWe start by installing and importing everything we need for this exercise:"}, {"metadata": {}, "cell_type": "code", "source": "!pip install --upgrade keras-applications keras-preprocessing setuptools tensorflow==1.14.0 keras==2.2.5", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Collecting keras-applications\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 13.7MB/s eta 0:00:01\n\u001b[?25hCollecting keras-preprocessing\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 16.9MB/s eta 0:00:01\n\u001b[?25hCollecting setuptools\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d5/444a443d890f09fc1ca1a2c3c9fc7e84cb148177b05ac94fe5084e3d9abb/setuptools-42.0.1-py2.py3-none-any.whl (582kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 583kB 19.0MB/s eta 0:00:01\n\u001b[?25hCollecting tensorflow==1.14.0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 109.2MB 59.8MB/s eta 0:00:01\n\u001b[?25hCollecting keras==2.2.5\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 337kB 54.3MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/Python36/lib/python3.6/site-packages (from keras-applications) (2.9.0)\nRequirement already satisfied, skipping upgrade: numpy>=1.9.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from keras-applications) (1.15.4)\nRequirement already satisfied, skipping upgrade: six>=1.9.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from keras-preprocessing) (1.12.0)\nRequirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14.0) (0.32.3)\nRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14.0) (0.7.1)\nCollecting tensorboard<1.15.0,>=1.14.0 (from tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.2MB 25.7MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: gast>=0.2.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14.0) (0.2.2)\nRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14.0) (3.6.1)\nRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14.0) (1.16.1)\nCollecting google-pasta>=0.1.6 (from tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 28.4MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14.0) (1.11.1)\nRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14.0) (0.7.0)\nRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14.0) (1.1.0)\nCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 491kB 55.3MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.14 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from keras==2.2.5) (1.2.0)\nRequirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/Python36/lib/python3.6/site-packages (from keras==2.2.5) (3.13)\nRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.0.1)\nRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.14.1)\nInstalling collected packages: keras-applications, keras-preprocessing, setuptools, tensorboard, google-pasta, tensorflow-estimator, tensorflow, keras\n  Found existing installation: Keras-Applications 1.0.6\n    Uninstalling Keras-Applications-1.0.6:\n      Successfully uninstalled Keras-Applications-1.0.6\n  Found existing installation: Keras-Preprocessing 1.0.5\n    Uninstalling Keras-Preprocessing-1.0.5:\n      Successfully uninstalled Keras-Preprocessing-1.0.5\n  Found existing installation: setuptools 40.8.0\n    Uninstalling setuptools-40.8.0:\n      Successfully uninstalled setuptools-40.8.0\n  Found existing installation: tensorflow-estimator 1.13.0\n    Uninstalling tensorflow-estimator-1.13.0:\n      Successfully uninstalled tensorflow-estimator-1.13.0\n  Found existing installation: tensorflow 1.13.1\n    Uninstalling tensorflow-1.13.1:\n      Successfully uninstalled tensorflow-1.13.1\n  Found existing installation: Keras 2.2.4\n    Uninstalling Keras-2.2.4:\n      Successfully uninstalled Keras-2.2.4\nSuccessfully installed google-pasta-0.1.8 keras-2.2.5 keras-applications-1.0.8 keras-preprocessing-1.1.0 setuptools-42.0.1 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import tensorflow\nif not tensorflow.__version__ == '1.14.0':\n    print(tensorflow.__version__)\n    raise ValueError('please upgrade to TensorFlow 1.14.0, or restart your Kernel (Kernel->Restart & Clear Output)')\n\nimport keras\nif not keras.__version__ == '2.2.5':\n    print(keras.__version__)\n    raise ValueError('please upgrade to Keras 2.2.5, or restart your Kernel (Kernel->Restart & Clear Output)')", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Using TensorFlow backend.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "IMPORTANT! => Please restart the kernel by clicking on \"Kernel\"->\"Restart and Clear Outout\" and wait until all output disapears. Then your changes are beeing picked up\n\nAs you can see, we use Keras' Sequential model with only two types of layers: Dense and Dropout. We also specify a random seed to make our results reproducible. Next, we load the Reuters data set:"}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.utils import to_categorical\nseed = 1337\nnp.random.seed(seed)\nfrom keras.datasets import reuters\n\nmax_words = 1000\n(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n                                                         test_split=0.2,\n                                                         seed=seed)\nnum_classes = np.max(y_train) + 1  # 46 topics", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n2113536/2110848 [==============================] - 0s 0us/step\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Note that we cap the maximum number of words in a news item to 1000 by specifying the *num_words* key word. Also, 20% of the data will be test data and we ensure reproducibility by setting our random seed.\n\nOur training features are still simply sequences of indexes and we need to further preprocess them, so that we can plug them into a *Dense* layer. For this we use a *Tokenizer* from Keras' text preprocessing module. This tokenizer will take an index sequence and map it to a vector of length *max_words=1000*. Each of the 1000 vector positions corresponds to one of the words in our newswire corpus. The output of the tokenizer has a 1 at the i-th position of the vector, if the word corresponding to i is in the description of the newswire, and 0 otherwise. Even if this word appears multiple times, we still just put a 1 into our vector, i.e. our tokenizer is binary. We use this tokenizer to transform both train and test features:"}, {"metadata": {}, "cell_type": "code", "source": "from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=max_words)\nx_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\nx_test = tokenizer.sequences_to_matrix(x_test, mode='binary')", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## 1. Exercise part: label encoding\n\nUse to_categorical, as we did in the lectures, to transform both *y_train* and *y_test* into one-hot encoded vectors of length *num_classes*:"}, {"metadata": {}, "cell_type": "code", "source": "y_train", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "array([ 4,  3,  3, ...,  3, 25, 11])"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "y_train = to_categorical(y_train, num_classes=num_classes, dtype='float32')\ny_test = to_categorical(y_train, num_classes=num_classes, dtype='float32')", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "y_test", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "array([[[1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.]],\n\n       ...,\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "##\u00a02. Exercise part: model definition\n\nNext, initialise a Keras *Sequential* model and add three layers to it:\n\n    Layer: Add a *Dense* layer with in input_shape=(max_words,), 512 output units and \"relu\" activation.\n    Layer: Add a *Dropout* layer with dropout rate of 50%.\n    Layer: Add a *Dense* layer with num_classes output units and \"softmax\" activation."}, {"metadata": {}, "cell_type": "code", "source": "model = Sequential() # Instantiate sequential model \nmodel.add(Dense(512, activation='relu',input_shape=(max_words,)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "WARNING: Logging before flag parsing goes to stderr.\nW1201 11:20:33.433211 140626773579584 deprecation_wrapper.py:119] From /opt/conda/envs/Python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nW1201 11:20:33.453645 140626773579584 deprecation_wrapper.py:119] From /opt/conda/envs/Python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nW1201 11:20:33.466640 140626773579584 deprecation_wrapper.py:119] From /opt/conda/envs/Python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nW1201 11:20:33.483376 140626773579584 deprecation_wrapper.py:119] From /opt/conda/envs/Python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n\nW1201 11:20:33.491875 140626773579584 deprecation.py:506] From /opt/conda/envs/Python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "raw", "source": "model.add(layers.Dense(3, activation='softmax'))\n\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))"}, {"metadata": {}, "cell_type": "markdown", "source": "## 3. Exercise part: model compilation\n\nAs the next step, we need to compile our Keras model with a training configuration. Compile your model with \"categorical_crossentropy\" as loss function, \"adam\" as optimizer and specify \"accuracy\" as evaluation metric. NOTE: In case you get an error regarding h5py, just restart the kernel and start from scratch"}, {"metadata": {}, "cell_type": "code", "source": "model.compile(optimizer='adam', \n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "W1201 11:20:33.525533 140626773579584 deprecation_wrapper.py:119] From /opt/conda/envs/Python36/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nW1201 11:20:33.556025 140626773579584 deprecation_wrapper.py:119] From /opt/conda/envs/Python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## 4. Exercise part: model training and evaluation\n\nNext, define the batch_size for training as 32 and train the model for 5 epochs on *x_train* and *y_train* by using the *fit* method of your model. Then calculate the score for your trained model by running *evaluate* on *x_test* and *y_test* with the same batch size as used in *fit*."}, {"metadata": {}, "cell_type": "code", "source": "batch_size = 32\nepochs=5\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n\n\nscore = model.evaluate(x_test, y_test)", "execution_count": 10, "outputs": [{"output_type": "error", "ename": "ValueError", "evalue": "Error when checking target: expected dense_2 to have shape (1,) but got array with shape (46,)", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)", "\u001b[0;32m<ipython-input-10-a8d2031a99fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/envs/Python36/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_2 to have shape (1,) but got array with shape (46,)"]}]}, {"metadata": {}, "cell_type": "markdown", "source": "If you have done everything as specified, in particular set the random seed as we did above, your test accuracy should be around 80% "}, {"metadata": {}, "cell_type": "code", "source": "score[1]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Congratulations, now it's time to submit your result to the Coursera grader by executing the following cells (Programming Assingment, Week2). \n\nWe have to install a little library in order to submit to coursera\n"}, {"metadata": {}, "cell_type": "code", "source": "!rm -f rklib.py\n!wget https://raw.githubusercontent.com/IBM/coursera/master/rklib.py", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Please provide your email address and obtain a submission token (secret) on the grader\u2019s submission page in coursera, then execute the cell"}, {"metadata": {}, "cell_type": "code", "source": "from rklib import submit\nimport json\n\nkey = \"XbAMqtjdEeepUgo7OOVwng\"\npart = \"HCvcp\"\nemail = ###_YOUR_CODE_GOES_HERE_###\ntoken = ###_YOUR_CODE_GOES_HERE_### #you can obtain it from the grader page on Coursera\n\n\nsubmit(email, token, 'XbAMqtjdEeepUgo7OOVwng', part, [part], json.dumps(score[1]*100))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "num_classes", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}